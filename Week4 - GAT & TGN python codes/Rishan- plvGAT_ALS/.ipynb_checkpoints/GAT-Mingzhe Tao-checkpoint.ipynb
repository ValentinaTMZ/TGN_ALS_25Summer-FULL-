{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09b72167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.2.0+cpu.html\n",
    "#!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.2.0+cpu.html\n",
    "#!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.2.0+cpu.html\n",
    "#!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.2.0+cpu.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "166ca22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa4343bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Jan 27 18:26:26 2024\n",
    "Rishan Patel, UCL, Bioelectronics Group.\n",
    "\n",
    "Building a dataset and testing a GNN model. \n",
    "\n",
    "FBCSP works very well. Clearly frequency information is important.\n",
    "Creating graphs based on full spectrum, raw data PLV. 3 Classes, L,R,Re.\n",
    "ICA not performed. \n",
    "Using 10 frequency bands, band power measures as features 22x10. \n",
    "Using a standard Graph Neural Network.\n",
    "\n",
    "To Do: \n",
    "- ICA for Brain Wave Isolation\n",
    "- Optimising parameters\n",
    "- Removing randomisation, and barching so that models update over sequential time\n",
    "- Check accuracies for each class, not aggregate\n",
    "\n",
    "Notes: \n",
    "    \n",
    "    \n",
    "\n",
    "https://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html#data-handling-of-graphs\n",
    "https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data\n",
    "https://pytorch-geometric.readthedocs.io/en/latest/tutorial/create_dataset.html\n",
    "\"\"\"\n",
    "import os\n",
    "from os.path import dirname, join as pjoin\n",
    "import scipy as sp\n",
    "import scipy.io as sio\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import specgram\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.signal as sig\n",
    "import networkx as nx\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import entropy\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from scipy.integrate import simps\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "import torch as torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00deed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, GATConv, GATv2Conv, GAT\n",
    "from torch_geometric.nn import global_mean_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a071de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % Preparing Data\n",
    "data_dir = os.getcwd()   # return the current working directory\n",
    "\n",
    "# Define the subject numbers\n",
    "subject_numbers = [1, 2, 5, 9, 21, 31, 34, 39]   # number each EEG subject with their EEG recordings\n",
    "\n",
    "# Dictionary to hold the loaded data for each subject\n",
    "subject_data = {} # create an empty dictionary to store the EED data from all subjects\n",
    "\n",
    "# Loop through the subject numbers and load the corresponding data\n",
    "for subject_number in subject_numbers: # go through each subject index, process each their .mat files\n",
    "    mat_fname = pjoin(data_dir, f'S{subject_number}.mat') # pjoin ensures cross-platform compatibility, constructs the full path to each .mat file\n",
    "    mat_contents = sio.loadmat(mat_fname) # use scipy.io.loadmat to process .mat files\n",
    "    subject_data[f'S{subject_number}'] = mat_contents[f'Subject{subject_number}'] # rename\n",
    "del subject_number,subject_numbers,mat_fname,mat_contents,data_dir # delete all other temporary variables that are no longer useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b822a346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e087aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Phase-GAT\n",
    "S1 = subject_data['S1'][:,:] # [:,:] selects all rows and all columns from Subject 1\n",
    "\n",
    "\n",
    "def plvfcn(eegData):\n",
    "    numElectrodes = eegData.shape[1]\n",
    "    numTimeSteps = eegData.shape[0] # T is the NO. of time points\n",
    "    plvMatrix = np.zeros((numElectrodes, numElectrodes)) \n",
    "    # generate a square 2D array with every element initialized to 0\n",
    "    for electrode1 in range(numElectrodes): # from 0 to numElectrodes\n",
    "        for electrode2 in range(electrode1 + 1, numElectrodes): # save computational load, from electrode1 + 1 to numElectrodes \n",
    "            #avoid repeating symmetric computations and self-PLV (PLV(i, j) == PLV(j, i))\n",
    "            phase1 = np.angle(sig.hilbert(eegData[:, electrode1])) # select all time steps for electrode 1\n",
    "            phase2 = np.angle(sig.hilbert(eegData[:, electrode2]))\n",
    "            # Hilbert Transform gives a complex number at each time point, including \n",
    "            # Real part: the original signal, and Imaginary part: the phase-shifted version\n",
    "            # np.angle() extracts the instantaneous phase (in radians) at each time point from the Hilbert result\n",
    "            phase_difference = phase2 - phase1\n",
    "            plv = np.abs(np.sum(np.exp(1j * phase_difference)) / numTimeSteps)\n",
    "            plvMatrix[electrode1, electrode2] = plv # calculate the upper triangle only\n",
    "            plvMatrix[electrode2, electrode1] = plv # To complete the symmetric matrix, we mirror it\n",
    "    return plvMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869823db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8ec0413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_plv(subject_data):\n",
    "    idx = ['L', 'R']\n",
    "    numElectrodes = subject_data['L'][0,1].shape[1] # ['L'][0,1] accesses one single EEG trial (row 0 and column 1)\n",
    "                                                    # .shape[1] gets the second dimension: No. of electrodes\n",
    "    plv = {field: np.zeros((numElectrodes, numElectrodes, subject_data.shape[1])) for field in idx}\n",
    "    # This creates an empty 3D numpy array for each of 'L' and 'R':\n",
    "    # plv shape: (electrodes × electrodes × trials)\n",
    "    # example: if 16 electrodes and 40 trials, shape is (16, 16, 40)\n",
    "    # subject_data.shape[1]: the number of trials per class, stores PLV matrices for each trial\n",
    "\n",
    "    \n",
    "    for i, field in enumerate(idx):\n",
    "        for j in range(subject_data.shape[1]):\n",
    "            x = subject_data[field][0, j]\n",
    "            plv[field][:, :, j] = plvfcn(x)\n",
    "    l, r = plv['L'], plv['R']\n",
    "    # Unpacks the full PLV arrays for each class\n",
    "    # l: shape (electrodes, electrodes, num_trials_L)\n",
    "    # r: shape (electrodes, electrodes, num_trials_R)\n",
    "    \n",
    "    yl, yr = np.zeros((subject_data.shape[1], 1)), np.ones((subject_data.shape[1], 1)) \n",
    "    # shape: No. of rows = subject_data.shape[1], No. of colume = 1\n",
    "    \n",
    "    img = np.concatenate((l, r), axis=2) \n",
    "    # concatenate all PLV matrices (left and right trials) along the third dimension\n",
    "    y = np.concatenate((yl, yr), axis=0)\n",
    "    y = torch.tensor(y, dtype=torch.long) \n",
    "    # In machine learning, tensors are multi-dimensional arrays used to represent data, e.g. vector, matrix...\n",
    "    # it converts the numpy label array into a PyTorch tensor with integer (long) data type, \n",
    "    # ready for model training\n",
    "    return img, y\n",
    "\n",
    "plv, y = compute_plv(S1) # S1 is the EEG data from Subject 1\n",
    "                         # This line runs the function and stores the PLV matrices and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b652e765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graphs(plv, threshold):\n",
    "    '''plv: a 3D numpy array of Phase Locking Value (PLV) matrices with shape (num_electrodes, num_electrodes, num_trials);\n",
    "       threshold: a float (e.g. 0.5), used to decide whether to add an edge between nodes (electrodes)'''\n",
    "    graphs = []\n",
    "    for i in range(plv.shape[2]): # plv.shape[2] is the number of trials\n",
    "        G = nx.Graph() # create an empty **undirected graph** using NetworkX\n",
    "        G.add_nodes_from(range(plv.shape[0])) # add a node for each electrode\n",
    "        for u in range(plv.shape[0]):\n",
    "            for v in range(plv.shape[0]):\n",
    "                if u != v and plv[u, v, i] > threshold: # u != v skips self-connections\n",
    "                    # plv[u, v, i] > threshold checks if the plv value is strong enough\n",
    "                    G.add_edge(u, v, weight=plv[u, v, i])\n",
    "        graphs.append(G)\n",
    "    return graphs\n",
    "threshold = 0.5\n",
    "graphs = create_graphs(plv, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "722db8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plv.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "254439f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numElectrodes = S1['L'][0,1].shape[1] # S1['L'][0,1] obtains the second EEG trial for Left-hand imagery\n",
    "                                      # .shape[1] accesses the No. of electrodes in that EEG trial\n",
    "adj = np.zeros([numElectrodes, numElectrodes, len(graphs)]) # No. of graphs = No. of trials\n",
    "for i, G in enumerate(graphs): # iterate through each graph G in the graphs list, where i is the index of the graph\n",
    "    adj[:, :, i] = nx.to_numpy_array(G)\n",
    "    # This gives a 2D matrix of shape (numElectrodes, numElectrodes) with:\n",
    "    # 0 if no edge between two electrodes\n",
    "    # PLV weight (e.g., 0.76) if there is an edge between them\n",
    "\n",
    "#% Initialize an empty list to store edge indices\n",
    "edge_indices = [] # % Edge indices are a list of source and target nodes in a graph. Think of it like the adjacency matrix\n",
    "\n",
    "# Iterate over the adjacency matrices\n",
    "for i in range(adj.shape[2]): # adj.shape[2] is the number of EEG trials, one trial creates one adjacent-matrix\n",
    "    # Initialize lists to store source and target nodes\n",
    "    source_nodes = []\n",
    "    target_nodes = []\n",
    "    # In PyG, we represent edges as pairs\n",
    "    \n",
    "    # Iterate through each element of the adjacency matrix\n",
    "    for row in range(adj.shape[0]):\n",
    "        for col in range(adj.shape[1]):\n",
    "            # Check if there's an edge\n",
    "            if adj[row, col, i] >= threshold:\n",
    "                # Add source and target nodes to the lists\n",
    "                source_nodes.append(row)\n",
    "                target_nodes.append(col)\n",
    "                # If the PLV between node u and v is ≥ threshold (e.g. 0.5), we consider this a valid edge.\n",
    "            else:\n",
    "                # If no edge exists, add placeholder zeros to maintain size\n",
    "                source_nodes.append(0)\n",
    "                target_nodes.append(0)\n",
    "    \n",
    "    # Create edge index as a LongTensor\n",
    "    edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "    # torch.tensor creates a tensor called edge_index from source and target nodes,\n",
    "    # which is the standard format for edge lists in PyTorch Geometric.\n",
    "    \n",
    "    # Append edge index to the list\n",
    "    edge_indices.append(edge_index)\n",
    "\n",
    "# Stack all edge indices along a new axis to create a 2D tensor\n",
    "edge_indices = torch.stack(edge_indices, dim=-1)\n",
    "\n",
    "del col,edge_index,i,row,source_nodes,target_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "234cb557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%\n",
    "\n",
    "def aggregate_eeg_data(S1,band): #%% This is to get the feat vector\n",
    "    \"\"\"\n",
    "    Aggregate EEG data for each class.\n",
    "\n",
    "    Parameters:\n",
    "        S1 (dict): Dictionary containing EEG data for each class. Keys are class labels, \n",
    "                   values are arrays of shape (2, num_samples, num_channels), where the first dimension\n",
    "                   corresponds to EEG data (index 0) and frequency data (index 1).\n",
    "\n",
    "    Returns:\n",
    "        l (ndarray): Aggregated EEG data for class 'L'.\n",
    "        r (ndarray): Aggregated EEG data for class 'R'.\n",
    "    \"\"\"\n",
    "    idx = ['L', 'R']\n",
    "    numElectrodes = S1['L'][0,1].shape[1];\n",
    "    max_sizes = {field: 0 for field in idx} # field = L or R, referring to two classes\n",
    "    # Initialize a dictionary to store the maximum time length of EEG signals for each class ('L' and 'R').\n",
    "\n",
    "    # Find the maximum size of EEG data for each class\n",
    "    for field in idx:\n",
    "        for i in range(S1[field].shape[1]):\n",
    "            max_sizes[field] = max(max_sizes[field], S1[field][0, i].shape[0])\n",
    "            # max_sizes[field] stores the sizes in time samples of each trial for each class (field)\n",
    "            # S1[field][0,i].shape[0] indexes the time sample dimension of each trial i, and each class (field)\n",
    "            # its consistently comparing old max to the latest variable in loop and seeing if its bigger than whats stored\n",
    "            # Go through every trial of 'L' and 'R'\n",
    "            # Find the longest time length across all trials of each class\n",
    "            # Store it in max_sizes['L'] and max_sizes['R']\n",
    "\n",
    "    # Initialize arrays to store aggregated EEG data\n",
    "    l = np.zeros((max_sizes['L'], numElectrodes, S1['L'].shape[1]))\n",
    "    r = np.zeros((max_sizes['R'], numElectrodes, S1['R'].shape[1]))\n",
    "\n",
    "    # Loop through each sample\n",
    "    # outer loop: over trial index i, inner loop: over classes 'L' and 'R'\n",
    "    for i in range(S1['L'].shape[1]):\n",
    "        for j, field in enumerate(idx):\n",
    "            x = S1[field][0, i]  # EEG data for the current sample\n",
    "            # Resize x to match the maximum size\n",
    "            resized_x = np.zeros((max_sizes[field], 22))\n",
    "            resized_x[:x.shape[0], :] = x\n",
    "            # Add the resized EEG data to the respective array\n",
    "            if field == 'L':\n",
    "                l[:, :, i] += resized_x\n",
    "            elif field == 'R':\n",
    "                r[:, :, i] += resized_x\n",
    "\n",
    "    l = l[..., np.newaxis]\n",
    "    l = np.copy(l) * np.ones(len(band)-1) # expand the data along a new dimension: frequency bands\n",
    "\n",
    "    r = r[..., np.newaxis]\n",
    "    r = np.copy(r) * np.ones(len(band)-1)\n",
    "    \n",
    "    return l, r\n",
    "\n",
    "band = list(range(8, 41, 4))\n",
    "l,r = aggregate_eeg_data(S1,band)\n",
    "l,r = np.transpose(l,[1,0,2,3]),np.transpose(r,[1,0,2,3])\n",
    "# from (time, electrodes, trials, bands) to (electrodes, time, trials, bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20b2b346",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 256 # fs: sampling frequency, 256 EEG signals are sampled per second\n",
    "\n",
    "def bandpass(data: np.ndarray, edges: list[float], sample_rate: float, poles: int = 5):\n",
    "    '''apply the Butterworth bandpass filter to the input EEG signal, in order to remove the un-useful frequency sections:\n",
    "       data: the raw EEG time-series signal (1D or 2D NumPy array)\n",
    "       edges: a two-element list, [low_cutoff, high_cutoff] in Hz\n",
    "       sample_rate: sampling frequency (e.g. 256 Hz)\n",
    "       poles: the filter order (default is 5). Higher = sharper filter'''\n",
    "    sos = sig.butter(poles, edges, 'bandpass', fs=sample_rate, output='sos')\n",
    "    filtered_data = sig.sosfiltfilt(sos, data)\n",
    "    return filtered_data\n",
    "\n",
    "for i in range(l.shape[3]): # l.shape[3] is the No. of bands\n",
    "    bp = [band[i],band[i+1]] # define the low and high frequency cutoffs\n",
    "    for j in range(l.shape[2]): # l.shape[2] is the No. of trials\n",
    "        l[:,:,j,i] = bandpass(l[:,:,j,i],bp,sample_rate=fs)\n",
    "        r[:,:,j,i] = bandpass(r[:,:,j,i],bp,sample_rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "772935b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#% Convert data from 22x1288x150xF to 22xFx150 where nodes x features x sample\n",
    "# features are BP of the band. \n",
    "\n",
    "def bandpower(data,low,high):\n",
    "    '''a common EEG feature that quantifies the strength of brain rhythms, in a particular frequency range'''\n",
    "\n",
    "    fs = 256\n",
    "    # Define window length (2s)\n",
    "    win = 2* fs\n",
    "    freqs, psd = signal.welch(data, fs, nperseg=win)\n",
    "    # Apply Welch’s method to estimate the power spectral density\n",
    "    \n",
    "    # Find intersecting values in frequency vector\n",
    "    idx_delta = np.logical_and(freqs >= low, freqs <= high)\n",
    "    \n",
    "    # # Plot the power spectral density and fill the delta area\n",
    "    # plt.figure(figsize=(7, 4))\n",
    "    # plt.plot(freqs, psd, lw=2, color='k')\n",
    "    # plt.fill_between(freqs, psd, where=idx_delta, color='skyblue')\n",
    "    # plt.xlabel('Frequency (Hz)')\n",
    "    # plt.ylabel('Power spectral density (uV^2 / Hz)')\n",
    "    # plt.xlim([0, 40])\n",
    "    # plt.ylim([0, psd.max() * 1.1])\n",
    "    # plt.title(\"Welch's periodogram\")\n",
    "    \n",
    "    # Frequency resolution\n",
    "    freq_res = freqs[1] - freqs[0]  # = 1 / 4 = 0.25\n",
    "    # for [8, 12] bandpass, we find which bins fall inside it by [8.0, 8.25, 8.5, ..., 12.0]\n",
    "    \n",
    "    # Compute the absolute power by approximating the area under the curve\n",
    "    power = simps(psd[idx_delta], dx=freq_res) # Simpson's rule: numerical intergral\n",
    "    \n",
    "    return power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9ef66da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Shape of l:\", l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dac1ce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tqdm import tqdm\n",
    "\n",
    "#def bandpowercalc(l, band, fs):\n",
    "    #x = np.zeros([l.shape[0], l.shape[3], l.shape[2]])\n",
    "    #for i in tqdm(range(l.shape[0]), desc=\"Subject\"):\n",
    "        #for j in range(l.shape[2]):  # sample\n",
    "            #for k in range(l.shape[3]):  # band\n",
    "                #data = l[i,:,j,k]\n",
    "                #low = band[k]\n",
    "                #high = band[k+1]\n",
    "                #x[i,k,j] = bandpower(data, low, high)\n",
    "    #return x\n",
    "\n",
    "\n",
    "#l_test = l[:1]\n",
    "#r_test = r[:1]\n",
    "\n",
    "#l_feat = bandpowercalc(l_test, band, fs)\n",
    "#r_feat = bandpowercalc(r_test, band, fs)\n",
    "\n",
    "#x = np.concatenate([l_feat, r_feat], axis=2)\n",
    "#x = torch.tensor(x, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe35561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87330a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7aeff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpowercalc(l,band,fs):  \n",
    "    '''transforms the filtered EEG signals into node-wide bandpower features'''\n",
    "    \n",
    "    x = np.zeros([l.shape[0],l.shape[3],l.shape[2]])\n",
    "    for i in range(l.shape[0]): #node\n",
    "        for j in range(l.shape[2]): #sample\n",
    "            for k in range(0,l.shape[3]): #band \n",
    "                # in this case, the loop order does not matter\n",
    "                data = l[i,:,j,k]\n",
    "                low = band[k]\n",
    "                high = band[k+1] # define low and high band edges\n",
    "                x[i,k,j] = bandpower(data,low,high)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3effe5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# could overload memory\n",
    "#l = bandpowercalc(l,band,fs)\n",
    "#r = bandpowercalc(r,band,fs)\n",
    "\n",
    "#x = np.concatenate([l,r],axis=2)\n",
    "#x = torch.tensor(x,dtype=torch.float32)\n",
    "\n",
    "#del r,l,S1,i,j,G,bp \n",
    "\n",
    "\n",
    "\n",
    "# try batch-wise bandpower features\n",
    "x_list = []  # store tensors batch by batch\n",
    "\n",
    "for i in range(l.shape[0]):  # loop over subjects\n",
    "    # extract one subject's data\n",
    "    l_i = l[i:i+1]\n",
    "    r_i = r[i:i+1]\n",
    "    \n",
    "    # compute features only for that subject\n",
    "    l_feat = bandpowercalc(l_i, band, fs)\n",
    "    r_feat = bandpowercalc(r_i, band, fs)\n",
    "    \n",
    "    # concatenate features\n",
    "    x_i = np.concatenate([l_feat, r_feat], axis=2)\n",
    "    \n",
    "    # convert to tensor and append\n",
    "    x_i = torch.tensor(x_i, dtype=torch.float32)\n",
    "    x_list.append(x_i)\n",
    "\n",
    "# stack all mini-tensors together\n",
    "x = torch.cat(x_list, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd296818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05c463e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "data_list = [] # create an empty Python list to hold one Data object per EEG trial.\n",
    "for i in range(np.size(adj,2)): # iterate through each trial\n",
    "    data_list.append(Data(x=x[:, :, i], edge_index=edge_indices[:,:,i], y=y[i, 0]))\n",
    "\n",
    "\n",
    "# def split(data_list, train_p, val_p, test_p):\n",
    "#     num_samples = len(data_list)\n",
    "#     a = num_samples // 3\n",
    "#     class_splits = [\n",
    "#         int(train_p * a), int(train_p * a), int(train_p * a),\n",
    "#         int(val_p * a), int(val_p * a), int(val_p * a),\n",
    "#         int(test_p * a), int(test_p * a), int(test_p * a)\n",
    "#     ]\n",
    "#     indices = list(range(num_samples))\n",
    "#     #np.random.shuffle(indices)\n",
    "    \n",
    "#     train_indices = indices[:sum(class_splits[:3])]\n",
    "#     val_indices = indices[sum(class_splits[:3]):sum(class_splits[:6])]\n",
    "#     test_indices = indices[sum(class_splits[:6]):]\n",
    "\n",
    "#     train_data = [data_list[i] for i in train_indices]\n",
    "#     val_data = [data_list[i] for i in val_indices]\n",
    "#     test_data = [data_list[i] for i in test_indices]\n",
    "\n",
    "#     return train_data, val_data, test_data\n",
    "\n",
    "\n",
    "# train,val,test = split(data_list,0.5,0,0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4b511f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#% split data so its sequentially 1,2,3\n",
    "# now the data_list is grouped by class: [L, L, L, ..., R, R, R, ...]\n",
    "\n",
    "datal =[] # store left-hand samples\n",
    "datar =[] # store right-hand samples\n",
    "size = len(data_list) # the total No. of trials\n",
    "idx = size//2\n",
    "c = [0,idx,idx*2,idx*3]\n",
    "\n",
    "datal = data_list[c[0]:c[1]]\n",
    "datar = data_list[c[1]:c[2]]\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for i in range(idx):\n",
    "    x = [datal[i],datar[i]] #datare[i]]\n",
    "    data_list.extend(x)\n",
    "    # ends up with [L, R, L, R, ...]\n",
    "\n",
    "\n",
    "size = len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e1a951e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize KFold with 5 splits\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m kf \u001b[38;5;241m=\u001b[39m KFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# use the K-Fold Cross-Validation to evaluate the Graph Neural Network (GNN)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# the dataset is split into K equal parts, called 'fold'; if K=2, we have two folds:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# fold 1: used for training in the first run, testing in the second;\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# List to store highest test accuracies of each fold\u001b[39;00m\n\u001b[1;32m     10\u001b[0m highest_test_accuracies \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'KFold' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize KFold with 5 splits\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "# use the K-Fold Cross-Validation to evaluate the Graph Neural Network (GNN)\n",
    "# the dataset is split into K equal parts, called 'fold'; if K=2, we have two folds:\n",
    "# fold 1: used for training in the first run, testing in the second;\n",
    "# fold 2: used for testing in the first run, training in the second;\n",
    "\n",
    "\n",
    "# List to store highest test accuracies of each fold\n",
    "highest_test_accuracies = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(data_list)):\n",
    "    # Create training and testing sets\n",
    "    train = [data_list[i] for i in train_idx]\n",
    "    test = [data_list[i] for i in test_idx]\n",
    "    # create lists of data objects (PyTorch Geometric graphs) using the split indices\n",
    "    \n",
    "    # Print the number of samples in train and test sets for each fold\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    print(f\"Train size: {len(train)}\")\n",
    "    print(f\"Test size: {len(test)}\")\n",
    "    print(\"=\" * 20)\n",
    "    \n",
    "    torch.manual_seed(12345) # torch.manual_seed(seed), use the same sequence of random numbers every time when running this script\n",
    "\n",
    "    train_loader = DataLoader(train, batch_size=8, shuffle=False)\n",
    "    test_loader = DataLoader(test, batch_size=8, shuffle=False)\n",
    "\n",
    "    for step, data in enumerate(train_loader):\n",
    "        print(f'Step {step + 1}:')\n",
    "        print('=======')\n",
    "        print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "        print(data)\n",
    "        print()\n",
    "        # print out the contents of the first few training batches — helpful for debugging.\n",
    "    \n",
    "    # class GCN(torch.nn.Module):\n",
    "    #     def __init__(self, hidden_channels):\n",
    "    #         super(GCN, self).__init__()\n",
    "    #         torch.manual_seed(12345)\n",
    "    #         self.conv1 = GCNConv(8, hidden_channels)  # num node features\n",
    "    #         self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "    #         self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "    #         self.lin = Linear(hidden_channels, 2)  # num of classes\n",
    "    \n",
    "    # defines a Graph Attention Network with 3 graph attention layers + 1 linear output layer\n",
    "    class GAT(torch.nn.Module):\n",
    "        def __init__(self, hidden_channels,heads):\n",
    "            super(GAT, self).__init__()\n",
    "            torch.manual_seed(12345)\n",
    "            \n",
    "            # Graph Convolution = Aggregating features from a node’s neighbors\n",
    "            # Each node updates its features based on:\n",
    "            # Its own current features\n",
    "            # The features of its neighbors\n",
    "            # The connection strengths (edge weights or attention scores)\n",
    "            \n",
    "            self.conv1 = GATv2Conv(8, hidden_channels, heads=heads, concat=True)  # num node features\n",
    "            # input: 8 features for each node\n",
    "            # output: each node will get (hidden_channels * heads) features\n",
    "            \n",
    "            self.conv2 = GATv2Conv(hidden_channels*heads, hidden_channels, heads=heads, concat=True)\n",
    "            self.conv3 = GATv2Conv(hidden_channels*heads, hidden_channels, heads=heads,concat=True)\n",
    "            self.lin = Linear(hidden_channels*heads, 2)  # two outputs, num of classes: 2\n",
    "\n",
    "        def forward(self, x, edge_index, batch):\n",
    "            # 1. Obtain node embeddings \n",
    "            x = self.conv1(x, edge_index)\n",
    "            x = x.relu()\n",
    "            x = self.conv2(x, edge_index)\n",
    "            x = x.relu()\n",
    "            x = self.conv3(x, edge_index)\n",
    "\n",
    "            # 2. Readout layer\n",
    "            x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "            # pools all node embeddings in each graph into a single graph embedding by averaging, \n",
    "            # to get the feature for each single graph\n",
    "\n",
    "            # 3. Apply a final classifier\n",
    "            x = F.dropout(x, p=0.5, training=self.training)\n",
    "            x = self.lin(x)\n",
    "            \n",
    "            return x\n",
    "\n",
    "    model = GAT(hidden_channels=64,heads=2)\n",
    "    \n",
    "    # use Adam optimizer and cross-entropy loss for classification (left vs right motor imagery)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def train():\n",
    "        model.train()\n",
    "        for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "            out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "            loss = criterion(out, data.y)  # Compute the loss.\n",
    "            loss.backward()  # Derive gradients, 'backpropagation'\n",
    "            optimizer.step()  # Update parameters based on gradients.\n",
    "            optimizer.zero_grad()  # Clear gradients.\n",
    "            # loops over all batches in the training set to:\n",
    "            # 1. compute output\n",
    "            # 2. calculate loss\n",
    "            # 3. backpropagate\n",
    "            # 4. update weights theta\n",
    "\n",
    "    def test(loader):\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "                out = model(data.x, data.edge_index, data.batch)  \n",
    "                pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "                correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "        return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "    # evaluate model accuracy (no gradient update):\n",
    "    # 1. take predictions out\n",
    "    # 2. choose the most likely class argmax\n",
    "    # 3. compare with ground-truth data.y\n",
    "\n",
    "\n",
    "    optimal = [0, 0, 0] \n",
    "    for epoch in range(1, 10): # run the training set for 200 epochs on the current fold\n",
    "        train()\n",
    "        train_acc = test(train_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        av_acc = np.mean([train_acc, test_acc])\n",
    "        \n",
    "        if test_acc > optimal[2]:\n",
    "            optimal[0] = av_acc\n",
    "            optimal[1] = train_acc\n",
    "            optimal[2] = test_acc\n",
    "        \n",
    "        print(f'Opt_Av: {optimal[0]:.4f}, Opt_Train: {optimal[1]:.4f}, Opt_Test: {optimal[2]:.4f}')\n",
    "\n",
    "    # Store the highest test accuracy of the current fold\n",
    "    highest_test_accuracies.append(optimal[2])\n",
    "    \n",
    "    import gc\n",
    "    \n",
    "    # after each fold finishes\n",
    "    del model, optimizer, criterion, train_loader, test_loader\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "# Calculate and print the mean of the highest test accuracies across all folds\n",
    "mean_highest_accuracy = np.mean(highest_test_accuracies)\n",
    "print(f'Mean Highest Test Accuracy Across 5 Folds: {mean_highest_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb3d6f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71d6f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191abe1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch_env)",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
